{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L 4-30-25\n",
    "# notebooks/classify_new_song.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd79625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/classify_new_song.ipynb\n",
    "#  Setup \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import joblib\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "#  Paths \n",
    "SONG_DIR = \"../data/Songs/\"\n",
    "OUTPUT_DIR = \"../reports/4_Classify_New_Song/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "RF_MODEL_PATH = \"../models/rf_model.pkl\"\n",
    "CNN_BUNDLE_PATH = \"../models/cnn_inference_bundle.pth\"\n",
    "CNNV2_BUNDLE_PATH = \"../models/cnnv2_inference_bundle.pth\"\n",
    "\n",
    "#  Load Random Forest Model \n",
    "rf_model = joblib.load(RF_MODEL_PATH)\n",
    "\n",
    "#  Load CNN Bundles \n",
    "cnn_bundle = torch.load(CNN_BUNDLE_PATH, map_location=\"cpu\")\n",
    "cnnv2_bundle = torch.load(CNNV2_BUNDLE_PATH, map_location=\"cpu\")\n",
    "\n",
    "cnn_transform = cnn_bundle['transform']\n",
    "cnnv2_transform = cnnv2_bundle['transform']\n",
    "\n",
    "cnn_classes = cnn_bundle['class_names']\n",
    "cnnv2_classes = cnnv2_bundle['class_names']\n",
    "\n",
    "#  Define CNN Models (matching training structure) \n",
    "\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 16, 3, 1, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(64 * 16 * 16, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "# CNNv2 (matching trained structure)\n",
    "\n",
    "\n",
    "class CNNv2(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, 3, padding=1), torch.nn.BatchNorm2d(\n",
    "                32), torch.nn.ReLU(), torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(32, 64, 3, padding=1), torch.nn.BatchNorm2d(\n",
    "                64), torch.nn.ReLU(), torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(64, 128, 3, padding=1), torch.nn.BatchNorm2d(\n",
    "                128), torch.nn.ReLU(), torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(128, 256, 3, padding=1), torch.nn.BatchNorm2d(\n",
    "                256), torch.nn.ReLU(), torch.nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc_block = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(256 * 8 * 8, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_block(self.conv_block(x))\n",
    "\n",
    "\n",
    "# Initialize and load weights\n",
    "cnn_model = SimpleCNN(num_classes=len(cnn_classes))\n",
    "cnn_model.load_state_dict(cnn_bundle['model_state_dict'])\n",
    "cnn_model.eval()\n",
    "\n",
    "cnnv2_model = CNNv2(num_classes=len(cnnv2_classes))\n",
    "cnnv2_model.load_state_dict(cnnv2_bundle['model_state_dict'])\n",
    "cnnv2_model.eval()\n",
    "\n",
    "#  Helpers \n",
    "\n",
    "\n",
    "def extract_mfcc(path):\n",
    "    y, sr = librosa.load(path, sr=None, duration=30)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    return np.concatenate([np.mean(mfcc, axis=1), np.std(mfcc, axis=1)])\n",
    "\n",
    "\n",
    "def generate_spectrogram(path, save_path=None):\n",
    "    y, sr = librosa.load(path, sr=None, duration=30)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    fig, ax = plt.subplots(figsize=(1.28, 1.28), dpi=100)\n",
    "    librosa.display.specshow(S_dB, sr=sr, cmap='viridis', ax=ax)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    return S_dB\n",
    "\n",
    "\n",
    "def classify_image(model, image_tensor, class_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor.unsqueeze(0))\n",
    "        probs = torch.nn.functional.softmax(output, dim=1).squeeze()\n",
    "        return class_names[probs.argmax().item()], probs.numpy()\n",
    "\n",
    "#  Inference Loop \n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for genre_dir in os.listdir(SONG_DIR):\n",
    "    genre_path = os.path.join(SONG_DIR, genre_dir)\n",
    "    if not os.path.isdir(genre_path):\n",
    "        continue\n",
    "\n",
    "    for fname in os.listdir(genre_path):\n",
    "        if not fname.endswith(\".mp3\"):\n",
    "            continue\n",
    "        fpath = os.path.join(genre_path, fname)\n",
    "        base_name = os.path.splitext(fname)[0]\n",
    "\n",
    "        try:\n",
    "            # === Random Forest ===\n",
    "            mfcc_vector = extract_mfcc(fpath).reshape(1, -1)\n",
    "            rf_pred = rf_model.predict(mfcc_vector)[0]\n",
    "\n",
    "            # === Spectrogram ===\n",
    "            spectro_path = os.path.join(OUTPUT_DIR, f\"{base_name}_spec.png\")\n",
    "            generate_spectrogram(fpath, save_path=spectro_path)\n",
    "\n",
    "            img = Image.open(spectro_path).convert(\"RGB\")\n",
    "\n",
    "            # === CNN ===\n",
    "            cnn_input = cnn_transform(img)\n",
    "            cnn_pred, cnn_probs = classify_image(\n",
    "                cnn_model, cnn_input, cnn_classes)\n",
    "\n",
    "            # === CNNv2 ===\n",
    "            cnnv2_input = cnnv2_transform(img)\n",
    "            cnnv2_pred, cnnv2_probs = classify_image(\n",
    "                cnnv2_model, cnnv2_input, cnnv2_classes)\n",
    "\n",
    "            # Save results\n",
    "            results.append({\n",
    "                \"file\": fname,\n",
    "                \"true_genre\": genre_dir,\n",
    "                \"RF\": rf_pred,\n",
    "                \"CNN\": cnn_pred,\n",
    "                \"CNNv2\": cnnv2_pred\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "# Save as CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(os.path.join(OUTPUT_DIR, \"all_model_predictions.csv\"), index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
